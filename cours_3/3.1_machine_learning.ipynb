{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Votre premier modèle de machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sélection de données pour la modélisation\n",
    "Votre ensemble de données comportait trop de variables à comprendre. Comment pouvez-vous réduire cette énorme quantité de données à quelque chose que vous pouvez comprendre ?\n",
    "\n",
    "Nous allons commencer par choisir quelques variables en utilisant notre intuition. Les cours ultérieurs vous montreront des techniques statistiques pour hiérarchiser automatiquement les variables.\n",
    "\n",
    "Pour choisir des variables/colonnes, nous aurons besoin de voir une liste de toutes les colonnes de l'ensemble de données. Cela se fait avec la propriété **colonnes** du DataFrame (la dernière ligne de code ci-dessous)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Suburb', 'Address', 'Rooms', 'Type', 'Price', 'Method', 'SellerG',\n",
       "       'Date', 'Distance', 'Postcode', 'Bedroom2', 'Bathroom', 'Car',\n",
       "       'Landsize', 'BuildingArea', 'YearBuilt', 'CouncilArea', 'Lattitude',\n",
       "       'Longtitude', 'Regionname', 'Propertycount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "melbourne_file_path = '../Data/data3/melb_data.csv'\n",
    "melbourne_data = pd.read_csv(melbourne_file_path) \n",
    "melbourne_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Melbourne data has some missing values (some houses for which some variables weren't recorded.)\n",
    "# Your Iowa data doesn't have missing values in the columns you use. \n",
    "# So we will take the simplest option for now, and drop houses from our data. \n",
    "# Don't worry about this much for now, though the code is:\n",
    "\n",
    "# dropna drops missing values (think of na as \"not available\")\n",
    "melbourne_data = melbourne_data.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il existe de nombreuses façons de sélectionner un sous-ensemble de vos données, mais nous allons nous concentrer sur deux approches pour le moment.\n",
    "\n",
    "1. La notation par points (dot-notation), que nous utilisons pour sélectionner la \"cible de prédiction\"\n",
    "2. Sélection avec une liste de colonnes, que nous utilisons pour sélectionner les « features »\n",
    "\n",
    "### Sélection de la cible de prédiction\n",
    "Vous pouvez extraire une variable avec **dot-notation**. Cette colonne unique est stockée dans une **Series**, qui ressemble globalement à un DataFrame avec une seule colonne de données.\n",
    "\n",
    "Nous utiliserons la notation par points pour sélectionner la colonne que nous voulons prédire, appelée **cible de prédiction**. Par convention, la cible de prédiction est appelée **y**. Ainsi, le code dont nous avons besoin pour enregistrer les prix des logements dans les données de Melbourne est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "y = melbourne_data.Price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choix des \"Features\"\n",
    "Les colonnes qui sont entrées dans notre modèle (et utilisées plus tard pour faire des prédictions) sont appelées « features ». Dans notre cas, ce seraient les colonnes utilisées pour déterminer le prix de la maison. Parfois, vous utiliserez toutes les colonnes sauf la cible comme features. D'autres fois, vous serez mieux avec moins de features.\n",
    "\n",
    "Pour l'instant, nous allons construire un modèle avec seulement quelques features. Plus tard, vous verrez comment itérer et comparer des modèles construits avec différentes features.\n",
    "\n",
    "Nous sélectionnons plusieurs features en fournissant une liste de noms de colonnes entre crochets. Chaque élément de cette liste doit être une chaîne (avec des guillemets).\n",
    "\n",
    "Voici un exemple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'Lattitude', 'Longtitude']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par convention, ces données sont appelées **X**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "X = melbourne_data[melbourne_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examinons rapidement les données que nous utiliserons pour prédire les prix des logements à l'aide de la méthode « describe » et de la méthode « head », qui affiche les quelques premières lignes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6196.000000</td>\n",
       "      <td>6196.000000</td>\n",
       "      <td>6196.000000</td>\n",
       "      <td>6196.000000</td>\n",
       "      <td>6196.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.931407</td>\n",
       "      <td>1.576340</td>\n",
       "      <td>471.006940</td>\n",
       "      <td>-37.807904</td>\n",
       "      <td>144.990201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.971079</td>\n",
       "      <td>0.711362</td>\n",
       "      <td>897.449881</td>\n",
       "      <td>0.075850</td>\n",
       "      <td>0.099165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-38.164920</td>\n",
       "      <td>144.542370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>-37.855438</td>\n",
       "      <td>144.926198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>373.000000</td>\n",
       "      <td>-37.802250</td>\n",
       "      <td>144.995800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>628.000000</td>\n",
       "      <td>-37.758200</td>\n",
       "      <td>145.052700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>37000.000000</td>\n",
       "      <td>-37.457090</td>\n",
       "      <td>145.526350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Rooms     Bathroom      Landsize    Lattitude   Longtitude\n",
       "count  6196.000000  6196.000000   6196.000000  6196.000000  6196.000000\n",
       "mean      2.931407     1.576340    471.006940   -37.807904   144.990201\n",
       "std       0.971079     0.711362    897.449881     0.075850     0.099165\n",
       "min       1.000000     1.000000      0.000000   -38.164920   144.542370\n",
       "25%       2.000000     1.000000    152.000000   -37.855438   144.926198\n",
       "50%       3.000000     1.000000    373.000000   -37.802250   144.995800\n",
       "75%       4.000000     2.000000    628.000000   -37.758200   145.052700\n",
       "max       8.000000     8.000000  37000.000000   -37.457090   145.526350"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>-37.8079</td>\n",
       "      <td>144.9934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>-37.8093</td>\n",
       "      <td>144.9944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>-37.8072</td>\n",
       "      <td>144.9941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>-37.8024</td>\n",
       "      <td>144.9993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>-37.8060</td>\n",
       "      <td>144.9954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rooms  Bathroom  Landsize  Lattitude  Longtitude\n",
       "1      2       1.0     156.0   -37.8079    144.9934\n",
       "2      3       2.0     134.0   -37.8093    144.9944\n",
       "4      4       1.0     120.0   -37.8072    144.9941\n",
       "6      3       2.0     245.0   -37.8024    144.9993\n",
       "7      2       1.0     256.0   -37.8060    144.9954"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérifier visuellement vos données avec ces commandes est une partie importante du travail d'un data scientist. Vous trouverez fréquemment des surprises dans l'ensemble de données qui méritent une inspection plus approfondie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construire votre modèle\n",
    "\n",
    "Vous utiliserez la bibliothèque **scikit-learn** pour créer vos modèles. Lors du codage, cette bibliothèque est écrite sous la forme **sklearn**, comme vous le verrez dans l'exemple de code. Scikit-learn est considérée la bibliothèque la plus populaire pour modéliser les types de données généralement stockées dans les DataFrames. \n",
    "\n",
    "Les étapes de création et d'utilisation d'un modèle sont les suivantes :\n",
    "* **Define:** What type of model will it be?  A decision tree?  Some other type of model? Some other parameters of the model type are specified too.\n",
    "* **Fit:** Capture patterns from provided data. This is the heart of modeling.\n",
    "* **Predict:** Just what it sounds like\n",
    "* **Evaluate**: Determine how accurate the model's predictions are.\n",
    "\n",
    "Voici un exemple de définition d'un modèle d'arbre de décision avec scikit-learn et son entrainement avec les features et la variable cible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(random_state=1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Define model. Specify a number for random_state to ensure same results each run\n",
    "melbourne_model = DecisionTreeRegressor(random_state=1)\n",
    "\n",
    "# Fit model\n",
    "melbourne_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De nombreux modèles d'apprentissage automatique autorisent un certain caractère aléatoire dans l'entraînement des modèles. La spécification d'un nombre pour « random_state » garantit que vous obtenez les mêmes résultats à chaque exécution. Ceci est considéré comme une bonne pratique. Vous utilisez n'importe quel nombre et la qualité du modèle ne dépendra pas de manière significative de la valeur que vous choisissez exactement.\n",
    "\n",
    "Nous avons maintenant un modèle entrainé que nous pouvons utiliser pour faire des prédictions.\n",
    "\n",
    "En pratique, vous voudrez faire des prévisions pour les nouvelles maisons à venir sur le marché plutôt que pour les maisons dont nous avons déjà les prix. Mais nous allons faire des prédictions pour les premières lignes des données d'apprentissage pour voir comment fonctionne la fonction de prédiction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions for the following 5 houses:\n",
      "   Rooms  Bathroom  Landsize  Lattitude  Longtitude\n",
      "1      2       1.0     156.0   -37.8079    144.9934\n",
      "2      3       2.0     134.0   -37.8093    144.9944\n",
      "4      4       1.0     120.0   -37.8072    144.9941\n",
      "6      3       2.0     245.0   -37.8024    144.9993\n",
      "7      2       1.0     256.0   -37.8060    144.9954\n",
      "The predictions are\n",
      "[1035000. 1465000. 1600000. 1876000. 1636000.]\n"
     ]
    }
   ],
   "source": [
    "print(\"Making predictions for the following 5 houses:\")\n",
    "print(X.head())\n",
    "print(\"The predictions are\")\n",
    "print(melbourne_model.predict(X.head()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code you have previously used to load data\n",
    "import pandas as pd\n",
    "\n",
    "# Path of the file to read\n",
    "iowa_file_path = '../Data/data3/train.csv'\n",
    "\n",
    "home_data = pd.read_csv(iowa_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Étape 1 : Spécifiez la cible de prédiction\n",
    "Sélectionnez la variable cible, qui correspond au prix de vente. Enregistrez-le dans une nouvelle variable appelée « y ». Vous devrez imprimer une liste des colonnes pour trouver le nom de la colonne dont vous avez besoin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the list of columns in the dataset to find the name of the prediction target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = ____\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Étape 2 : Créer X\n",
    "Vous allez maintenant créer un DataFrame appelé « X » contenant les features prédictives.\n",
    "\n",
    "Puisque vous ne voulez que quelques colonnes des données d'origine, vous allez d'abord créer une liste avec les noms des colonnes que vous voulez dans `X`.\n",
    "\n",
    "Vous n'utiliserez que les colonnes suivantes dans la liste :\n",
    "    * LotArea\n",
    "    * YearBuilt\n",
    "    * 1stFlrSF\n",
    "    * 2ndFlrSF\n",
    "    * FullBath\n",
    "    * BedroomAbvGr\n",
    "    * TotRmsAbvGrd\n",
    "Après avoir créé cette liste de features, utilisez-la pour créer le DataFrame que vous utiliserez pour entrainer le modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the list of features below\n",
    "feature_names = ___\n",
    "\n",
    "# Select data corresponding to features in feature_names\n",
    "X = ____\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examiner les données\n",
    "Avant de créer un modèle, jetez un coup d'œil à **X** pour vérifier qu'il semble raisonnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review data\n",
    "# print description or statistics from X\n",
    "#print(_)\n",
    "\n",
    "# print the top few lines\n",
    "#print(_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Étape 3 : Spécifiez et ajustez le modèle\n",
    "Créez un `DecisionTreeRegressor` et enregistrez-le dans iowa_model. Assurez-vous d'avoir effectué l'importation appropriée depuis sklearn pour exécuter cette commande.\n",
    "\n",
    "Ensuite, entrainer le modèle que vous venez de créer en utilisant les données dans « X » et « y » que vous avez enregistrées ci-dessus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from _ import _\n",
    "#specify the model. \n",
    "#For model reproducibility, set a numeric value for random_state when specifying the model\n",
    "iowa_model = ____\n",
    "\n",
    "# Fit the model\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Étape 4 : Faire des prédictions\n",
    "Faites des prédictions avec la commande \"predict\" du modèle en utilisant \"X\" comme données. Enregistrez les résultats dans une variable appelée « prédictions »."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = ____\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pensez à vos résultats\n",
    "\n",
    "Utilisez la méthode « head » pour comparer les quelques prédictions les plus élevées aux valeurs réelles des maisons (en « y ») pour ces mêmes maisons. Rien de surprenant ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can write code in this cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Validation du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous voudrez évaluer presque tous les modèles que vous construisez. Dans la plupart des applications (mais pas toutes), la mesure pertinente de la qualité du modèle est la précision prédictive. En d'autres termes, les prédictions du modèle seront-elles proches de ce qui se passe réellement.\n",
    "\n",
    "Beaucoup de gens font une énorme erreur lorsqu'ils mesurent la précision prédictive. Ils font des prédictions avec leurs *données d'entraînement* et comparent ces prédictions aux valeurs cibles dans les *données d'entraînement*. Vous verrez le problème avec cette approche et comment le résoudre dans un instant, mais réfléchissons d'abord à la façon dont nous procéderions.\n",
    "\n",
    "Vous devez d'abord résumer la qualité du modèle de manière compréhensible. Si vous comparez les valeurs prédites et réelles des maisons pour 10 000 maisons, vous trouverez probablement un mélange de bonnes et de mauvaises prédictions. Parcourir une liste de 10 000 valeurs prédites et réelles serait inutile. Nous devons résumer cela en une seule métrique.\n",
    "\n",
    "Il existe de nombreuses métriques pour résumer la qualité du modèle, mais nous commencerons par une métrique appelée **Mean Absolute Error** (également appelée **MAE**). Décomposons cette métrique en commençant par le dernier mot, erreur.\n",
    "\n",
    "L'erreur de prédiction pour chaque maison est : <br>\n",
    "```\n",
    "erreur=réelle−prédite\n",
    "```\n",
    " \n",
    "Ainsi, si une maison coûte 150 000 \\\\$ et que vous avez prédit qu'elle coûterait 100 000 \\\\$, l'erreur est de 50 000 \\$.\n",
    "\n",
    "Avec la métrique MAE, nous prenons la valeur absolue de chaque erreur. Cela convertit chaque erreur en un nombre positif. Nous prenons ensuite la moyenne de ces erreurs absolues. C'est notre mesure de la qualité du modèle. En clair, on peut dire\n",
    "\n",
    "> En moyenne, nos prévisions sont erronées d'environ X.\n",
    "\n",
    "Pour calculer la MAE, nous avons d'abord besoin d'un modèle. Cela est construit dans la cellule ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Loading Code Hidden Here\n",
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "melbourne_file_path = '../Data/data3/melb_data.csv'\n",
    "melbourne_data = pd.read_csv(melbourne_file_path) \n",
    "# Filter rows with missing price values\n",
    "filtered_melbourne_data = melbourne_data.dropna(axis=0)\n",
    "# Choose target and features\n",
    "y = filtered_melbourne_data.Price\n",
    "melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'BuildingArea', \n",
    "                        'YearBuilt', 'Lattitude', 'Longtitude']\n",
    "X = filtered_melbourne_data[melbourne_features]\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "# Define model\n",
    "melbourne_model = DecisionTreeRegressor()\n",
    "# Fit model\n",
    "melbourne_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois que nous avons un modèle, voici comment nous calculons l'erreur absolue moyenne :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "434.71594577146544"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "predicted_home_prices = melbourne_model.predict(X)\n",
    "mean_absolute_error(y, predicted_home_prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Le problème des scores « dans l'échantillon »\n",
    "\n",
    "La mesure que nous venons de calculer peut être appelée un score \"dans l'échantillon\". Nous avons utilisé un seul « échantillon » de maisons à la fois pour construire le modèle et pour l'évaluer. Voici pourquoi c'est mauvais.\n",
    "\n",
    "Imaginez que, sur le grand marché immobilier, la couleur de la porte n'est pas liée au prix de la maison.\n",
    "\n",
    "Cependant, dans l'échantillon de données que vous avez utilisé pour construire le modèle, toutes les maisons avec des portes vertes étaient très chères. Le travail du modèle est de trouver des patterns qui prédisent les prix des maisons, il verra donc ce pattern, et il prédira toujours les prix élevés des maisons avec des portes vertes.\n",
    "\n",
    "Étant donné que ce modèle a été dérivé des données d'entraînement, le modèle apparaîtra précis dans les données d'entraînement.\n",
    "\n",
    "Mais si ce modèle ne tient pas lorsque le modèle voit de nouvelles données, le modèle serait très imprécis lorsqu'il est utilisé dans la pratique.\n",
    "\n",
    "Étant donné que la valeur pratique des modèles provient de la réalisation de prédictions sur de nouvelles données, nous mesurons les performances sur des données qui n'ont pas été utilisées pour construire le modèle. Le moyen le plus simple de procéder consiste à exclure certaines données du processus de création de modèle, puis à les utiliser pour tester la précision du modèle sur des données qu'il n'a jamais vues auparavant. Ces données sont appelées **données de validation**.\n",
    "\n",
    "\n",
    "## Le coder\n",
    "\n",
    "\n",
    "La bibliothèque scikit-learn a une fonction `train_test_split` pour diviser les données en deux morceaux. Nous utiliserons certaines de ces données comme données d'apprentissage pour entrainer le modèle, et nous utiliserons les autres données comme données de validation pour calculer \"mean_absolute_error\".\n",
    "\n",
    "Voici le code :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264004.1310522918\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data into training and validation data, for both features and target\n",
    "# The split is based on a random number generator. Supplying a numeric value to\n",
    "# the random_state argument guarantees we get the same split every time we\n",
    "# run this script.\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0)\n",
    "# Define model\n",
    "melbourne_model = DecisionTreeRegressor()\n",
    "# Fit model\n",
    "melbourne_model.fit(train_X, train_y)\n",
    "\n",
    "# get predicted prices on validation data\n",
    "val_predictions = melbourne_model.predict(val_X)\n",
    "print(mean_absolute_error(val_y, val_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wow!\n",
    "\n",
    "Votre erreur absolue moyenne pour les données de l'échantillon était d'environ 500 dollars. Hors échantillon, c'est plus de 250 000 dollars.\n",
    "\n",
    "C'est la différence entre un modèle qui est presque tout à fait exact et un autre qui est inutilisable dans la plupart des cas. À titre de référence, la valeur moyenne des maisons dans les données de validation est de 1,1 million de dollars. Ainsi, l'erreur dans les nouvelles données est d'environ un quart de la valeur moyenne de la maison.\n",
    "\n",
    "Il existe de nombreuses façons d'améliorer ce modèle, telles que l'expérimentation pour trouver de meilleures features ou différents types de modèles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First in-sample predictions: [208500. 181500. 223500. 140000. 250000.]\n",
      "Actual target values for those homes: [208500, 181500, 223500, 140000, 250000]\n"
     ]
    }
   ],
   "source": [
    "# Code you have previously used to load data\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Path of the file to read\n",
    "iowa_file_path = '../Data/data3/train.csv'\n",
    "\n",
    "home_data = pd.read_csv(iowa_file_path)\n",
    "y = home_data.SalePrice\n",
    "feature_columns = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n",
    "X = home_data[feature_columns]\n",
    "\n",
    "# Specify Model\n",
    "iowa_model = DecisionTreeRegressor()\n",
    "# Fit Model\n",
    "iowa_model.fit(X, y)\n",
    "\n",
    "print(\"First in-sample predictions:\", iowa_model.predict(X.head()))\n",
    "print(\"Actual target values for those homes:\", y.head().tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Étape 1 : Divisez vos données\n",
    "Utilisez la fonction `train_test_split` pour diviser vos données.\n",
    "\n",
    "Donnez-lui l'argument `random_state=1`.\n",
    "\n",
    "Rappelez-vous, vos features sont chargées dans le DataFrame **X** et votre cible est chargée dans **y**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the train_test_split function and uncomment\n",
    "# from _ import _\n",
    "\n",
    "# fill in and uncomment\n",
    "# train_X, val_X, train_y, val_y = ____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Étape 2 : Spécifiez et entrainez le modèle\n",
    "\n",
    "Créez un modèle « DecisionTreeRegressor » et entrainez-le avec des données pertinentes.\n",
    "Définissez à nouveau `random_state` à 1 lors de la création du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You imported DecisionTreeRegressor in your last exercise\n",
    "# and that code has been copied to the setup code above. So, no need to\n",
    "# import it again\n",
    "\n",
    "# Specify the model\n",
    "iowa_model = ____\n",
    "\n",
    "# Fit iowa_model with the training data.\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Étape 3 : Faire des prédictions avec des données de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict with all validation observations\n",
    "val_predictions = ____\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspectez vos prédictions et valeurs réelles à partir des données de validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the top few validation predictions\n",
    "print(____)\n",
    "# print the top few actual prices from validation data\n",
    "print(____)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Que remarquez-vous de différent de ce que vous avez vu avec les prédictions dans l'échantillon (qui sont imprimées après la cellule de code supérieure de cette page).\n",
    "\n",
    "Vous souvenez-vous pourquoi les prédictions de validation diffèrent des prédictions dans l'échantillon (ou d'apprentissage) ? C'est une idée importante de la dernière leçon.\n",
    "\n",
    "### Étape 4 : Calculer l'erreur absolue moyenne dans les données de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "val_mae = ____\n",
    "\n",
    "# uncomment following line to see the validation_mae\n",
    "#print(val_mae)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Est-ce que le MAE est bon ? Il n'y a pas de règle générale sur les bonnes valeurs qui s'applique à toutes les applications. Mais vous verrez comment utiliser (et améliorer) ce nombre à l'étape suivante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Sous-apprentissage et sur-apprentissage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que vous disposez d'un moyen fiable de mesurer la précision d'un modèle, vous pouvez expérimenter avec des modèles alternatifs et voir lequel donne les meilleures prédictions. Mais quelles alternatives avez-vous pour les modèles ?\n",
    "\n",
    "Vous pouvez voir dans la [documentation](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html) de scikit-learn que le modèle d'arbre de décision a de nombreuses options (plus que vous ne voudrez ou besoin depuis longtemps). Les options les plus importantes déterminent la profondeur de l'arbre.\n",
    "\n",
    "En pratique, il n'est pas rare qu'un arbre ait 10 niveaux entre le niveau supérieur (toutes les maisons) et une feuille. Au fur et à mesure que l'arbre s'approfondit, l'ensemble de données est découpé en feuilles avec moins de maisons. Si un arbre n'avait qu'une division, il divise les données en 2 groupes. Si chaque groupe est à nouveau divisé, nous obtiendrons 4 groupes de maisons. Diviser chacun d'eux à nouveau créerait 8 groupes. Si nous continuons à doubler le nombre de groupes en ajoutant plus de divisions à chaque niveau, nous aurons \\\\(2^{10}\\\\) groupes de maisons au moment où nous arrivons au 10ème niveau. Cela fait 1024 feuilles.\n",
    "\n",
    "Lorsque nous divisons les maisons entre plusieurs feuilles, nous avons également moins de maisons dans chaque feuille. Les feuilles avec très peu de maisons feront des prédictions assez proches des valeurs réelles de ces maisons, mais elles peuvent faire des prédictions très peu fiables pour les nouvelles données (car chaque prédiction est basée sur quelques maisons seulement).\n",
    "\n",
    "Il s'agit d'un phénomène appelé **sur-apprentissage**, dans lequel un modèle correspond presque parfaitement aux données d'entraînement, mais ne réussit pas bien dans la validation et dans d'autres nouvelles données. D'un autre côté, si nous rendons notre arbre très peu profond, il ne divise pas les maisons en groupes très distincts.\n",
    "\n",
    "À l'extrême, si un arbre divise les maisons en seulement 2 ou 4, chaque groupe a toujours une grande variété de maisons. Les prédictions résultantes peuvent être éloignées pour la plupart des maisons, même dans les données d'entraînement (et ce sera également mauvais en validation pour la même raison). Lorsqu'un modèle ne parvient pas à capturer les distinctions et les modèles importants dans les données, il fonctionne donc mal même dans les données d'entraînement, cela s'appelle **sous-ajustement**.\n",
    "\n",
    "Étant donné que nous nous soucions de la précision des nouvelles données, que nous estimons à partir de nos données de validation, nous voulons trouver le juste milieu entre le sous-apprentissage et le surapprentissage. Visuellement, nous voulons le point bas de la courbe de validation (rouge) dans la figure ci-dessous.\n",
    "\n",
    "## Exemple\n",
    "Il existe quelques alternatives pour contrôler la profondeur de l'arbre, et beaucoup permettent à certains itinéraires à travers l'arbre d'avoir une plus grande profondeur que d'autres itinéraires. Mais l'argument *max_leaf_nodes* fournit un moyen très judicieux de contrôler le surapprentissage par rapport au sous-apprentissage. Plus nous permettons au modèle de faire des feuilles, plus nous passons de la zone de sous-ajustement dans le graphique ci-dessus à la zone de sur-ajustement.\n",
    "\n",
    "Nous pouvons utiliser une fonction utilitaire pour aider à comparer les scores MAE à partir de différentes valeurs pour *max_leaf_nodes* :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):\n",
    "    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n",
    "    model.fit(train_X, train_y)\n",
    "    preds_val = model.predict(val_X)\n",
    "    mae = mean_absolute_error(val_y, preds_val)\n",
    "    return(mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les données sont chargées dans **train_X**, **val_X**, **train_y** et **val_y** en utilisant le code que vous avez déjà vu (et que vous avez déjà écrit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading Code Runs At This Point\n",
    "import pandas as pd\n",
    "    \n",
    "# Load data\n",
    "melbourne_file_path = '../Data/data3/melb_data.csv'\n",
    "melbourne_data = pd.read_csv(melbourne_file_path) \n",
    "# Filter rows with missing values\n",
    "filtered_melbourne_data = melbourne_data.dropna(axis=0)\n",
    "# Choose target and features\n",
    "y = filtered_melbourne_data.Price\n",
    "melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'BuildingArea', \n",
    "                        'YearBuilt', 'Lattitude', 'Longtitude']\n",
    "X = filtered_melbourne_data[melbourne_features]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data into training and validation data, for both features and target\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons utiliser une boucle for pour comparer la précision des modèles construits avec différentes valeurs pour *max_leaf_nodes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max leaf nodes: 5  \t\t Mean Absolute Error:  347380\n",
      "Max leaf nodes: 50  \t\t Mean Absolute Error:  258171\n",
      "Max leaf nodes: 500  \t\t Mean Absolute Error:  243495\n",
      "Max leaf nodes: 5000  \t\t Mean Absolute Error:  254983\n"
     ]
    }
   ],
   "source": [
    "# compare MAE with differing values of max_leaf_nodes\n",
    "for max_leaf_nodes in [5, 50, 500, 5000]:\n",
    "    my_mae = get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y)\n",
    "    print(\"Max leaf nodes: %d  \\t\\t Mean Absolute Error:  %d\" %(max_leaf_nodes, my_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parmi les options répertoriées, 500 est le nombre optimal de feuilles.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Voici ce qu'il faut retenir : les modèles peuvent souffrir de :\n",
    "- **Sur-apprentissage :** capture de modèles parasites qui ne se reproduiront pas à l'avenir, entraînant des prédictions moins précises, ou\n",
    "- **Sous-apprentissage :** échec à capturer les modèles pertinents, ce qui conduit à nouveau à des prédictions moins précises.\n",
    "\n",
    "Nous utilisons des données de **validation**, qui ne sont pas utilisées dans l'entraînement des modèles, pour mesurer la précision d'un modèle candidat. Cela nous permet d'essayer de nombreux modèles candidats et de garder le meilleur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MAE: 29,653\n"
     ]
    }
   ],
   "source": [
    "# Code you have previously used to load data\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "# Path of the file to read\n",
    "iowa_file_path = '../Data/data3/train.csv'\n",
    "\n",
    "home_data = pd.read_csv(iowa_file_path)\n",
    "# Create target object and call it y\n",
    "y = home_data.SalePrice\n",
    "# Create X\n",
    "features = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n",
    "X = home_data[features]\n",
    "\n",
    "# Split into validation and training data\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n",
    "\n",
    "# Specify Model\n",
    "iowa_model = DecisionTreeRegressor(random_state=1)\n",
    "# Fit Model\n",
    "iowa_model.fit(train_X, train_y)\n",
    "\n",
    "# Make validation predictions and calculate mean absolute error\n",
    "val_predictions = iowa_model.predict(val_X)\n",
    "val_mae = mean_absolute_error(val_predictions, val_y)\n",
    "print(\"Validation MAE: {:,.0f}\".format(val_mae))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):\n",
    "    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n",
    "    model.fit(train_X, train_y)\n",
    "    preds_val = model.predict(val_X)\n",
    "    mae = mean_absolute_error(val_y, preds_val)\n",
    "    return(mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Étape 1 : comparer différentes tailles d'arbres\n",
    "Écrivez une boucle qui essaie les valeurs suivantes pour *max_leaf_nodes* à partir d'un ensemble de valeurs possibles.\n",
    "\n",
    "Appelez la fonction *get_mae* sur chaque valeur de max_leaf_nodes. Stockez la sortie d'une manière qui vous permet de sélectionner la valeur de `max_leaf_nodes` qui donne le modèle le plus précis sur vos données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_max_leaf_nodes = [5, 25, 50, 100, 250, 500]\n",
    "# Write loop to find the ideal tree size from candidate_max_leaf_nodes\n",
    "_\n",
    "\n",
    "# Store the best value of max_leaf_nodes (it will be either 5, 25, 50, 100, 250 or 500)\n",
    "best_tree_size = ____\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Étape 2 : Entrainer le modèle avec toutes les données\n",
    "Vous connaissez la meilleure taille d'arbre. Si vous deviez déployer ce modèle dans la pratique, vous le rendriez encore plus précis en utilisant toutes les données et en conservant cette taille d'arbre. C'est-à-dire que vous n'avez pas besoin de conserver les données de validation maintenant que vous avez pris toutes vos décisions de modélisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in argument to make optimal size and uncomment\n",
    "# final_model = DecisionTreeRegressor(____)\n",
    "\n",
    "# fit the final model and uncomment the next two lines\n",
    "# final_model.fit(____, ____)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
