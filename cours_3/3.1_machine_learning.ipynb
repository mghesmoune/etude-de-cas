{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Votre premier modèle de machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sélection de données pour la modélisation\n",
    "Supposant que votre jeu de données comporte trop de variables à comprendre. Comment pouvez-vous réduire cette énorme quantité de données à quelque chose que vous pouvez comprendre ?\n",
    "\n",
    "Nous allons commencer par choisir quelques variables en utilisant notre intuition. Les cours ultérieurs vous montreront des techniques statistiques pour hiérarchiser automatiquement les variables.\n",
    "\n",
    "Pour choisir des variables/colonnes, nous aurons besoin de voir une liste de toutes les colonnes de l'ensemble de données. Cela se fait avec la propriété **columns** du DataFrame (la dernière ligne de code ci-dessous)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "melbourne_file_path = '../Data/data3/melb_data.csv'\n",
    "melbourne_data = pd.read_csv(melbourne_file_path) \n",
    "melbourne_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Melbourne data has some missing values (some houses for which some variables weren't recorded.)\n",
    "# Your Iowa data doesn't have missing values in the columns you use. \n",
    "# So we will take the simplest option for now, and drop houses from our data. \n",
    "# Don't worry about this much for now, though the code is:\n",
    "\n",
    "# dropna drops missing values (think of na as \"not available\")\n",
    "melbourne_data = melbourne_data.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il existe de nombreuses façons de sélectionner un sous-ensemble de vos données, mais nous allons nous concentrer sur deux approches pour le moment.\n",
    "\n",
    "1. La notation par points (dot-notation), que nous utilisons pour sélectionner la \"cible de prédiction\"\n",
    "2. Sélection avec une liste de colonnes, que nous utilisons pour sélectionner les « features »\n",
    "\n",
    "### Sélection de la cible de prédiction\n",
    "Vous pouvez extraire une variable avec **dot-notation**. Cette colonne unique est stockée dans une **Series**, qui ressemble globalement à un DataFrame avec une seule colonne de données.\n",
    "\n",
    "Nous utiliserons la notation par points pour sélectionner la colonne que nous voulons prédire, appelée **cible de prédiction**. Par convention, la cible de prédiction est appelée **y**. Ainsi, le code dont nous avons besoin pour enregistrer les prix des logements dans les données de Melbourne est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "y = melbourne_data.Price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choix des Features\n",
    "Les colonnes qui sont entrées dans notre modèle (et utilisées plus tard pour faire des prédictions) sont appelées « features ». Dans notre cas, ce seraient les colonnes utilisées pour déterminer le prix de la maison. Parfois, vous utiliserez toutes les colonnes sauf la cible comme features. D'autres fois, vous serez mieux avec moins de features.\n",
    "\n",
    "Pour l'instant, nous allons construire un modèle avec seulement quelques features. Plus tard, vous verrez comment itérer et comparer des modèles construits avec différentes features.\n",
    "\n",
    "Nous sélectionnons plusieurs features en fournissant une liste de noms de colonnes entre crochets. Chaque élément de cette liste doit être une chaîne (avec des guillemets).\n",
    "\n",
    "Voici un exemple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'Lattitude', 'Longtitude']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par convention, ces données sont appelées **X**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "X = melbourne_data[melbourne_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examinons rapidement les données que nous utiliserons pour prédire les prix des logements à l'aide de la méthode « describe » et de la méthode « head », qui affiche les quelques premières lignes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérifier visuellement vos données avec ces commandes est une partie importante du travail d'un data scientist. Vous trouverez fréquemment des surprises dans l'ensemble de données qui méritent une inspection plus approfondie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construire votre modèle\n",
    "\n",
    "Vous utiliserez la bibliothèque **scikit-learn** pour créer vos modèles. Lors du codage, cette bibliothèque est écrite sous la forme **sklearn**, comme vous le verrez dans l'exemple de code. Scikit-learn est considérée comme étant la bibliothèque la plus populaire pour modéliser les types de données généralement stockées dans des DataFrames. \n",
    "\n",
    "Les étapes de création et d'utilisation d'un modèle sont les suivantes :\n",
    "* **Define:** What type of model will it be?  A decision tree?  Some other type of model? Some other parameters of the model type are specified too.\n",
    "* **Fit:** Capture patterns from provided data. This is the heart of modeling (**the training step**).\n",
    "* **Predict:** Just what it sounds like (**the inference or prediction step**).\n",
    "* **Evaluate**: Determine how accurate the model's predictions are.\n",
    "\n",
    "Voici un exemple de définition d'un modèle d'arbre de décision (regarder la [documentation ici](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html#sklearn.tree.DecisionTreeRegressor)) avec scikit-learn et son entrainement avec les features et la variable cible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Define model. Specify a number for random_state to ensure same results each run\n",
    "melbourne_model = DecisionTreeRegressor(random_state=1)\n",
    "\n",
    "# Fit model\n",
    "melbourne_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De nombreux modèles d'apprentissage automatique autorisent un certain caractère aléatoire dans l'entraînement des modèles. La spécification d'un nombre pour « random_state » garantit que vous obtenez les mêmes résultats à chaque exécution. Ceci est considéré comme une bonne pratique. Vous utilisez n'importe quel nombre et la qualité du modèle ne dépendra pas de manière significative de la valeur que vous choisissez exactement.\n",
    "\n",
    "Nous avons maintenant un modèle entrainé que nous pouvons utiliser pour faire des prédictions.\n",
    "\n",
    "En pratique, vous voudrez faire des prévisions pour les nouvelles maisons à venir sur le marché plutôt que pour les maisons dont nous avons déjà les prix. Mais nous allons faire des prédictions pour les premières lignes des données d'apprentissage pour voir comment fonctionne la fonction de prédiction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"Making predictions for the following 5 houses:\")\n",
    "print(X.head())\n",
    "print(\"The predictions are\")\n",
    "print(melbourne_model.predict(X.head()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code you have previously used to load data\n",
    "import pandas as pd\n",
    "\n",
    "# Path of the file to read\n",
    "iowa_file_path = '../Data/data3/train.csv'\n",
    "\n",
    "home_data = pd.read_csv(iowa_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Étape 1 : Spécifiez la cible de prédiction\n",
    "Sélectionnez la variable cible, qui correspond au prix de vente. Enregistrez-le dans une nouvelle variable appelée « y ». Vous devrez imprimer une liste des colonnes pour trouver le nom de la colonne dont vous avez besoin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the list of columns in the dataset to find the name of the prediction target\n",
    "home_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = ____\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Étape 2 : Créer X\n",
    "Vous allez maintenant créer un DataFrame appelé « X » contenant les features prédictives.\n",
    "\n",
    "Puisque vous ne voulez que quelques colonnes des données d'origine, vous allez d'abord créer une liste avec les noms des colonnes que vous voulez dans `X`.\n",
    "\n",
    "Vous n'utiliserez que les colonnes suivantes dans la liste :\n",
    "\n",
    "    * LotArea \n",
    "    * YearBuilt \n",
    "    * 1stFlrSF \n",
    "    * 2ndFlrSF \n",
    "    * FullBath \n",
    "    * BedroomAbvGr \n",
    "    * TotRmsAbvGrd \n",
    "    \n",
    "Après avoir créé cette liste de features, utilisez-la pour créer le DataFrame que vous utiliserez pour entrainer le modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the list of features below\n",
    "feature_names = ___\n",
    "\n",
    "# Select data corresponding to features in feature_names\n",
    "X = ____\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examiner les données\n",
    "Avant de créer un modèle, jetez un coup d'œil à **X** pour vérifier qu'il semble raisonnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review data\n",
    "# print description or statistics from X\n",
    "#print(_)\n",
    "\n",
    "# print the top few lines\n",
    "#print(_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Étape 3 : Spécifiez et ajustez le modèle\n",
    "\n",
    "1) Décrivez le fonctionnement des arbres de décision ? quels sont leurs avantages et limites ? citez les différentes implémentations (algorithmes) ? Comment utiliser un arbre de décision sur de nouvelles données ? quelle est la différence entre `DecisionTreeRegressor` et `DecisionTreeClassifier`\n",
    "\n",
    "2) Créez un `DecisionTreeRegressor` et enregistrez-le dans iowa_model. Assurez-vous d'avoir effectué l'importation appropriée depuis sklearn pour exécuter cette commande.\n",
    "\n",
    "3) Ensuite, entrainer le modèle que vous venez de créer en utilisant les données dans « X » et « y » que vous avez enregistrées ci-dessus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from _ import _\n",
    "#specify the model. \n",
    "#For model reproducibility, set a numeric value for random_state when specifying the model\n",
    "iowa_model = ____\n",
    "\n",
    "# Fit the model\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Étape 4 : Faire des prédictions\n",
    "Faites des prédictions avec la méthode \"predict\" du modèle en utilisant \"X\" comme données. Enregistrez les résultats dans une variable appelée « prédictions »."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = ____\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pensez à vos résultats\n",
    "\n",
    "Utilisez la méthode « head » pour comparer les quelques prédictions les plus élevées aux valeurs réelles des maisons (en « y ») pour ces mêmes maisons. Rien de surprenant ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can write code in this cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Validation du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous voudrez évaluer presque tous les modèles que vous construisez. Dans la plupart des applications (mais pas toutes), la mesure pertinente de la qualité du modèle est la précision prédictive. En d'autres termes, les prédictions du modèle seront-elles proches de ce qui se passe réellement.\n",
    "\n",
    "Beaucoup de gens font une énorme erreur lorsqu'ils mesurent la précision prédictive. Ils font des prédictions avec leurs *données d'entraînement* et comparent ces prédictions aux valeurs cibles dans les *données d'entraînement*. Vous verrez le problème avec cette approche et comment le résoudre dans un instant, mais réfléchissons d'abord à la façon dont nous procéderions.\n",
    "\n",
    "Vous devez d'abord résumer la qualité du modèle de manière compréhensible. Si vous comparez les valeurs prédites et réelles des maisons pour 10 000 maisons, vous trouverez probablement un mélange de bonnes et de mauvaises prédictions. Parcourir une liste de 10 000 valeurs prédites et réelles serait inutile. Nous devons résumer cela en une seule métrique.\n",
    "\n",
    "Il existe de nombreuses métriques pour résumer la qualité du modèle, mais nous commencerons par une métrique appelée **Mean Absolute Error** (également appelée **MAE**). Décomposons cette métrique en commençant par le dernier mot, erreur.\n",
    "\n",
    "L'erreur de prédiction pour chaque maison est : <br>\n",
    "```\n",
    "erreur=réelle−prédite\n",
    "```\n",
    " \n",
    "Ainsi, si une maison coûte 150 000 \\\\$ et que vous avez prédit qu'elle coûterait 100 000 \\\\$, l'erreur est de 50 000 \\$.\n",
    "\n",
    "Avec la métrique MAE, nous prenons la valeur absolue de chaque erreur. Cela convertit chaque erreur en un nombre positif. Nous prenons ensuite la moyenne de ces erreurs absolues. C'est notre mesure de la qualité du modèle. En clair, on peut dire\n",
    "\n",
    "> En moyenne, nos prévisions sont erronées d'environ N.\n",
    "\n",
    "Pour calculer la MAE, nous avons d'abord besoin d'un modèle. Cela est construit dans la cellule ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading Code Hidden Here\n",
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "melbourne_file_path = '../Data/data3/melb_data.csv'\n",
    "melbourne_data = pd.read_csv(melbourne_file_path) \n",
    "\n",
    "# Filter rows with missing price values\n",
    "filtered_melbourne_data = melbourne_data.dropna(axis=0)\n",
    "\n",
    "# Choose target and features\n",
    "y = filtered_melbourne_data.Price\n",
    "melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'BuildingArea', \n",
    "                        'YearBuilt', 'Lattitude', 'Longtitude']\n",
    "X = filtered_melbourne_data[melbourne_features]\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Define model\n",
    "melbourne_model = DecisionTreeRegressor()\n",
    "\n",
    "# Fit model\n",
    "melbourne_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois que nous avons un modèle, voici comment nous calculons l'erreur absolue moyenne :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "predicted_home_prices = melbourne_model.predict(X)\n",
    "mean_absolute_error(y, predicted_home_prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Le problème des scores « dans l'échantillon »\n",
    "\n",
    "La mesure que nous venons de calculer peut être appelée un score \"dans l'échantillon\". Nous avons utilisé un seul « échantillon » de maisons à la fois pour construire le modèle et pour l'évaluer. Voici pourquoi c'est mauvais.\n",
    "\n",
    "Imaginez que, sur le grand marché immobilier, la couleur de la porte n'est pas liée au prix de la maison.\n",
    "\n",
    "Cependant, dans l'échantillon de données que vous avez utilisé pour construire le modèle, toutes les maisons avec des portes vertes étaient très chères. Le travail du modèle est de trouver des patterns qui prédisent les prix des maisons, il verra donc ce pattern, et il prédira toujours les prix élevés des maisons avec des portes vertes.\n",
    "\n",
    "Étant donné que ce modèle a été dérivé des données d'entraînement, le modèle apparaîtra précis dans les données d'entraînement.\n",
    "\n",
    "Mais si ce modèle ne tient pas lorsque le modèle voit de nouvelles données, le modèle serait très imprécis lorsqu'il est utilisé dans la pratique.\n",
    "\n",
    "Étant donné que la valeur pratique des modèles provient de la réalisation de prédictions sur de nouvelles données, nous mesurons les performances sur des données qui n'ont pas été utilisées pour construire le modèle. Le moyen le plus simple de procéder consiste à exclure certaines données du processus de création de modèle, puis de les utiliser pour tester la précision du modèle sur des données qu'il n'a jamais vues auparavant. Ces données sont appelées **données de validation**.\n",
    "\n",
    "\n",
    "## Le coder\n",
    "\n",
    "\n",
    "La bibliothèque scikit-learn a une fonction `train_test_split` pour diviser les données en deux parties. Nous utiliserons certaines de ces données comme données d'apprentissage pour entrainer le modèle, et nous utiliserons les autres données comme données de validation pour calculer \"mean_absolute_error\".\n",
    "\n",
    "Voici le code :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data into training and validation data, for both features and target\n",
    "# The split is based on a random number generator. Supplying a numeric value to\n",
    "# the random_state argument guarantees we get the same split every time we\n",
    "# run this script.\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "# Define model\n",
    "melbourne_model = DecisionTreeRegressor()\n",
    "\n",
    "# Fit model\n",
    "melbourne_model.fit(train_X, train_y)\n",
    "\n",
    "# get predicted prices on validation data\n",
    "val_predictions = melbourne_model.predict(val_X)\n",
    "\n",
    "print(mean_absolute_error(val_y, val_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wow!\n",
    "\n",
    "Votre erreur absolue moyenne pour les données de l'échantillon était d'environ 500 dollars. Hors échantillon, c'est plus de 250 000 dollars.\n",
    "\n",
    "C'est la différence entre un modèle qui est presque tout à fait exact et un autre qui est inutilisable dans la plupart des cas. À titre de référence, la valeur moyenne des maisons dans les données de validation est de 1,1 million de dollars. Ainsi, l'erreur dans les nouvelles données est d'environ un quart de la valeur moyenne de la maison.\n",
    "\n",
    "Il existe de nombreuses façons d'améliorer ce modèle, telles que l'expérimentation pour trouver de meilleures features ou différents types de modèles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code you have previously used to load data\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Path of the file to read\n",
    "iowa_file_path = '../Data/data3/train.csv'\n",
    "\n",
    "home_data = pd.read_csv(iowa_file_path)\n",
    "y = home_data.SalePrice\n",
    "feature_columns = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n",
    "X = home_data[feature_columns]\n",
    "\n",
    "# Specify Model\n",
    "iowa_model = DecisionTreeRegressor()\n",
    "\n",
    "# Fit Model\n",
    "iowa_model.fit(X, y)\n",
    "\n",
    "print(\"First in-sample predictions:\", iowa_model.predict(X.head()))\n",
    "print(\"Actual target values for those homes:\", y.head().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Étape 1 : Divisez vos données\n",
    "Utilisez la fonction `train_test_split` pour diviser vos données.\n",
    "\n",
    "Donnez-lui l'argument `random_state=1`.\n",
    "\n",
    "Rappelez-vous, vos features sont chargées dans le DataFrame **X** et votre cible est chargée dans **y**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the train_test_split function and uncomment\n",
    "# from _ import _\n",
    "\n",
    "# fill in and uncomment\n",
    "# train_X, val_X, train_y, val_y = ____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Étape 2 : Spécifiez et entrainez le modèle\n",
    "\n",
    "Créez un modèle « DecisionTreeRegressor » et entrainez-le avec des données pertinentes.\n",
    "Définissez à nouveau `random_state` à 1 lors de la création du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You imported DecisionTreeRegressor in your last exercise\n",
    "# and that code has been copied to the setup code above. So, no need to\n",
    "# import it again\n",
    "\n",
    "# Specify the model\n",
    "iowa_model = ____\n",
    "\n",
    "# Fit iowa_model with the training data.\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Étape 3 : Faire des prédictions avec des données de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict with all validation observations\n",
    "val_predictions = ____\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspectez vos prédictions et valeurs réelles à partir des données de validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the top few validation predictions\n",
    "print(____)\n",
    "# print the top few actual prices from validation data\n",
    "print(____)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Que remarquez-vous de différent de ce que vous avez vu avec les prédictions dans l'échantillon (qui sont imprimées après la cellule de code supérieure de cette page).\n",
    "\n",
    "Vous souvenez-vous pourquoi les prédictions de validation diffèrent des prédictions dans l'échantillon (ou d'apprentissage) ?\n",
    "\n",
    "### Étape 4 : Calculer l'erreur absolue moyenne dans les données de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "val_mae = ____\n",
    "\n",
    "# uncomment following line to see the validation_mae\n",
    "#print(val_mae)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Est-ce que le MAE est bon ? Il n'y a pas de règle générale sur les bonnes valeurs qui s'applique à toutes les applications. Mais vous verrez comment utiliser (et améliorer) ce nombre à l'étape suivante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Sous-apprentissage et sur-apprentissage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que vous disposez d'un moyen fiable pour mesurer la précision d'un modèle, vous pouvez expérimenter avec des modèles alternatifs et voir lequel donne les meilleures prédictions. Mais quelles alternatives avez-vous pour les modèles ?\n",
    "\n",
    "Vous pouvez voir dans la [documentation](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html) de scikit-learn que le modèle d'arbre de décision a de nombreuses options (plus que vous ne voudrez ou besoin depuis longtemps). Les options les plus importantes déterminent la profondeur de l'arbre.\n",
    "\n",
    "En pratique, il n'est pas rare qu'un arbre ait 10 niveaux entre le niveau supérieur (toutes les maisons) et une feuille. Au fur et à mesure que l'arbre s'approfondit, l'ensemble de données est découpé en feuilles avec moins de maisons. Si un arbre n'avait qu'une division, il divise les données en 2 groupes. Si chaque groupe est à nouveau divisé, nous obtiendrons 4 groupes de maisons. Diviser chacun d'eux à nouveau créerait 8 groupes. Si nous continuons à doubler le nombre de groupes en ajoutant plus de divisions à chaque niveau, nous aurons \\\\(2^{10}\\\\) groupes de maisons au moment où nous arrivons au 10ème niveau. Cela fait 1024 feuilles.\n",
    "\n",
    "Lorsque nous divisons les maisons entre plusieurs feuilles, nous avons également moins de maisons dans chaque feuille. Les feuilles avec très peu de maisons feront des prédictions assez proches des valeurs réelles de ces maisons, mais elles peuvent faire des prédictions très peu fiables pour les nouvelles données (car chaque prédiction est basée sur quelques maisons seulement).\n",
    "\n",
    "Il s'agit d'un phénomène appelé **sur-apprentissage**, dans lequel un modèle correspond presque parfaitement aux données d'entraînement, mais ne réussit pas bien dans la validation et dans d'autres nouvelles données. D'un autre côté, si nous rendons notre arbre très peu profond, il ne divise pas les maisons en groupes très distincts.\n",
    "\n",
    "À l'extrême, si un arbre divise les maisons en seulement 2 ou 4, chaque groupe a toujours une grande variété de maisons. Les prédictions résultantes peuvent être éloignées pour la plupart des maisons, même dans les données d'entraînement (et ce sera également mauvais en validation pour la même raison). Lorsqu'un modèle ne parvient pas à capturer les distinctions et les patterns importants dans les données, il fonctionne donc mal même dans les données d'entraînement, cela s'appelle **sous-apprentissage**.\n",
    "\n",
    "Étant donné que nous nous soucions de la précision des nouvelles données, que nous estimons à partir de nos données de validation, nous voulons trouver le juste milieu entre le sous-apprentissage et le sur-apprentissage.\n",
    "\n",
    "## Exemple\n",
    "Il existe quelques alternatives pour contrôler la profondeur de l'arbre, et beaucoup permettent à certains itinéraires à travers l'arbre d'avoir une plus grande profondeur que d'autres itinéraires. Mais l'argument *max_leaf_nodes* fournit un moyen très judicieux de contrôler le surapprentissage par rapport au sous-apprentissage. Plus nous permettons au modèle de faire des feuilles, plus nous passons de la zone de sous-apprentissage à la zone de sur-apprentissage.\n",
    "\n",
    "Nous pouvons utiliser une fonction utilitaire pour aider à comparer les scores MAE à partir de différentes valeurs pour *max_leaf_nodes* :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):\n",
    "    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n",
    "    model.fit(train_X, train_y)\n",
    "    preds_val = model.predict(val_X)\n",
    "    mae = mean_absolute_error(val_y, preds_val)\n",
    "    return(mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les données sont chargées dans **train_X**, **val_X**, **train_y** et **val_y** en utilisant le code que vous avez déjà vu (et que vous avez déjà écrit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading Code Runs At This Point\n",
    "import pandas as pd\n",
    "    \n",
    "# Load data\n",
    "melbourne_file_path = '../Data/data3/melb_data.csv'\n",
    "melbourne_data = pd.read_csv(melbourne_file_path) \n",
    "\n",
    "# Filter rows with missing values\n",
    "filtered_melbourne_data = melbourne_data.dropna(axis=0)\n",
    "\n",
    "# Choose target and features\n",
    "y = filtered_melbourne_data.Price\n",
    "melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'BuildingArea', \n",
    "                        'YearBuilt', 'Lattitude', 'Longtitude']\n",
    "X = filtered_melbourne_data[melbourne_features]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data into training and validation data, for both features and target\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons utiliser une boucle for pour comparer la précision des modèles construits avec différentes valeurs pour *max_leaf_nodes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare MAE with differing values of max_leaf_nodes\n",
    "for max_leaf_nodes in [5, 50, 500, 5000]:\n",
    "    my_mae = get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y)\n",
    "    print(\"Max leaf nodes: %d  \\t\\t Mean Absolute Error:  %d\" %(max_leaf_nodes, my_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parmi les options répertoriées, 500 est le nombre optimal de feuilles.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Voici ce qu'il faut retenir : les modèles peuvent souffrir de :\n",
    "- **Sur-apprentissage :** capture de patterns parasites qui ne se reproduiront pas à l'avenir, entraînant des prédictions moins précises, ou\n",
    "- **Sous-apprentissage :** échec à capturer les patterns pertinents, ce qui conduit à nouveau à des prédictions moins précises.\n",
    "\n",
    "  Nous utilisons des données de **validation**, qui ne sont pas utilisées dans l'entraînement des modèles, pour mesurer la précision d'un modèle candidat. Cela nous permet d'essayer de nombreux modèles candidats et de garder le meilleur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code you have previously used to load data\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "# Path of the file to read\n",
    "iowa_file_path = '../Data/data3/train.csv'\n",
    "\n",
    "home_data = pd.read_csv(iowa_file_path)\n",
    "# Create target object and call it y\n",
    "y = home_data.SalePrice\n",
    "# Create X\n",
    "features = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n",
    "X = home_data[features]\n",
    "\n",
    "# Split into validation and training data\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n",
    "\n",
    "# Specify Model\n",
    "iowa_model = DecisionTreeRegressor(random_state=1)\n",
    "# Fit Model\n",
    "iowa_model.fit(train_X, train_y)\n",
    "\n",
    "# Make validation predictions and calculate mean absolute error\n",
    "val_predictions = iowa_model.predict(val_X)\n",
    "val_mae = mean_absolute_error(val_predictions, val_y)\n",
    "print(\"Validation MAE: {:,.0f}\".format(val_mae))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):\n",
    "    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n",
    "    model.fit(train_X, train_y)\n",
    "    preds_val = model.predict(val_X)\n",
    "    mae = mean_absolute_error(val_y, preds_val)\n",
    "    return(mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Étape 1 : comparer différentes tailles d'arbres\n",
    "Écrivez une boucle qui essaie les valeurs suivantes pour *max_leaf_nodes* à partir d'un ensemble de valeurs possibles.\n",
    "\n",
    "Appelez la fonction *get_mae* sur chaque valeur de max_leaf_nodes. Stockez la sortie d'une manière qui vous permet de sélectionner la valeur de `max_leaf_nodes` qui donne le modèle le plus précis sur vos données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_max_leaf_nodes = [_, _, _, etc. ]\n",
    "# Write loop to find the ideal tree size from candidate_max_leaf_nodes\n",
    "___\n",
    "\n",
    "# Store the best value of max_leaf_nodes\n",
    "best_tree_size = ____\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Étape 2 : Entrainer le modèle avec toutes les données\n",
    "Vous connaissez la meilleure taille d'arbre. Si vous deviez déployer ce modèle dans la pratique, vous le rendriez encore plus précis en utilisant toutes les données et en conservant cette taille d'arbre. C'est-à-dire que vous n'avez pas besoin de conserver les données de validation maintenant que vous avez pris toutes vos décisions de modélisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in argument to make optimal size and uncomment\n",
    "# final_model = DecisionTreeRegressor(____)\n",
    "\n",
    "# fit the final model \n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable catégorielle\n",
    "\n",
    "Une variable catégorielle ne prend qu'un nombre limité de valeurs.\n",
    "\n",
    "  -  Considérez une enquête qui vous demande à quelle fréquence vous prenez votre petit-déjeuner et propose quatre options : « Jamais », « Rarement », « La plupart des jours » ou « Tous les jours ». Dans ce cas, les données sont catégorielles, car les réponses appartiennent à un ensemble fixe de catégories.\n",
    "  -  Si les gens répondaient à un sondage sur la marque de voiture qu'ils possédaient, les réponses seraient classées dans des catégories telles que \"Honda\", \"Toyota\" et \"Ford\". Dans ce cas, les données sont également catégorielles.\n",
    "\n",
    "Vous obtiendrez une erreur si vous essayez de connecter ces variables à la plupart des modèles d'apprentissage automatique en Python sans les prétraiter au préalable. Dans ce tutoriel, nous allons voir l'approche la plus utilisée pour préparer vos données catégorielles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding\n",
    "\n",
    "Le One-Hot Encoding crée de nouvelles colonnes indiquant la présence (ou l'absence) de chaque valeur possible dans les données d'origine. Pour comprendre cela, nous allons travailler à travers un exemple.\n",
    "\n",
    "Etant donné un jeu de données contenant une variable catégorielle (colonne) appelée « Couleur » avec trois catégories : « Rouge », « Jaune » et « Vert ». L'encodage one-hot correspondant contient une colonne pour chaque valeur possible et une ligne pour chaque ligne du jeu de données d'origine. Partout où la valeur d'origine était « Rouge », nous avons mis un 1 dans la colonne « Rouge » ; si la valeur d'origine était \"Jaune\", on met un 1 dans la colonne \"Jaune\", et ainsi de suite.\n",
    "\n",
    "L'encodage one-hot ne suppose pas un ordre des catégories (**dans le cas contraire, il faut utiliser l'encodage ordinal**). Ainsi, vous pouvez vous attendre à ce que cette approche fonctionne particulièrement bien s'il n'y a pas d'ordre clair dans les données catégorielles (par exemple, « Rouge » n'est ni plus ni moins que « Jaune »). Nous appelons variables nominales les variables catégorielles sans classement intrinsèque.\n",
    "\n",
    "L'encodage one-hot ne fonctionne généralement pas bien si la variable catégorielle prend un grand nombre de valeurs (c'est-à-dire que vous ne l'utiliserez généralement pas pour des variables prenant plus de 15 valeurs différentes).\n",
    "\n",
    "**Exemple**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the data\n",
    "data = pd.read_csv('../Data/data3/melb_data.csv')\n",
    "\n",
    "# Separate target from predictors\n",
    "y = data.Price\n",
    "X = data.drop(['Price'], axis=1)\n",
    "\n",
    "# Divide data into training and validation subsets\n",
    "X_train_full, X_valid_full, y_train, y_valid = train_test_split(\n",
    "                                                    X, y, train_size=0.8, test_size=0.2, random_state=0)\n",
    "\n",
    "# Drop columns with missing values (simplest approach)\n",
    "cols_with_missing = [col for col in X_train_full.columns if X_train_full[col].isnull().any()] \n",
    "X_train_full.drop(cols_with_missing, axis=1, inplace=True)\n",
    "X_valid_full.drop(cols_with_missing, axis=1, inplace=True)\n",
    "\n",
    "# \"Cardinality\" means the number of unique values in a column\n",
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "low_cardinality_cols = [cname for cname in X_train_full.columns if X_train_full[cname].nunique() < 10 and \n",
    "                        X_train_full[cname].dtype == \"object\"]\n",
    "\n",
    "# Select numerical columns\n",
    "numerical_cols = [cname for cname in X_train_full.columns if X_train_full[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "# Keep selected columns only\n",
    "my_cols = low_cardinality_cols + numerical_cols\n",
    "X_train = X_train_full[my_cols].copy()\n",
    "X_valid = X_valid_full[my_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of categorical variables\n",
    "s = (X_train.dtypes == 'object')\n",
    "object_cols = list(s[s].index)\n",
    "\n",
    "print(\"Categorical variables:\")\n",
    "print(object_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(y_valid, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardez la documentation de la [méthode OneHotEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) de scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Apply one-hot encoder to each column with categorical data\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[object_cols]))\n",
    "OH_cols_valid = pd.DataFrame(OH_encoder.transform(X_valid[object_cols]))\n",
    "\n",
    "# One-hot encoding removed index; put it back\n",
    "OH_cols_train.index = X_train.index\n",
    "OH_cols_valid.index = X_valid.index\n",
    "\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_X_train = X_train.drop(object_cols, axis=1)\n",
    "num_X_valid = X_valid.drop(object_cols, axis=1)\n",
    "\n",
    "# Add one-hot encoded columns to numerical features\n",
    "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n",
    "\n",
    "print(\"MAE from One-Hot Encoding:\") \n",
    "print(score_dataset(OH_X_train, OH_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the data\n",
    "X = pd.read_csv('../Data/data3/train.csv', index_col='Id') \n",
    "X_test = pd.read_csv('../Data/data3/test.csv', index_col='Id')\n",
    "\n",
    "# Remove rows with missing target, separate target from predictors\n",
    "X.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "y = X.SalePrice\n",
    "X.drop(['SalePrice'], axis=1, inplace=True)\n",
    "\n",
    "# To keep things simple, we'll drop columns with missing values\n",
    "cols_with_missing = [col for col in X.columns if X[col].isnull().any()] \n",
    "X.drop(cols_with_missing, axis=1, inplace=True)\n",
    "X_test.drop(cols_with_missing, axis=1, inplace=True)\n",
    "\n",
    "# Break off validation set from training data\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y,\n",
    "                                                      train_size=0.8, test_size=0.2,\n",
    "                                                      random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notez que l'ensemble de données contient à la fois des variables numériques et catégorielles. Vous devrez encoder les données catégorielles avant d'entraîner un modèle.\n",
    "Pour comparer différents modèles, vous utiliserez la même fonction score_dataset() du tutoriel. Cette fonction rapporte l'erreur absolue moyenne (MAE) à partir d'un modèle de forêt aléatoire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Étape 1 : Supprimer les colonnes contenant des données catégorielles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the lines below: drop columns in training and validation data\n",
    "drop_X_train = ____\n",
    "drop_X_valid = ____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MAE from Approach 1 (Drop categorical variables):\")\n",
    "print(score_dataset(drop_X_train, drop_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Unique values in 'Condition2' column in training data:\", X_train['Condition2'].unique())\n",
    "print(\"\\nUnique values in 'Condition2' column in validation data:\", X_valid['Condition2'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qu'est-ce que vous remarquez ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Étape 2 : encodage ordinal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical columns in the training data\n",
    "object_cols = [col for col in X_train.columns if X_train[col].dtype == \"object\"]\n",
    "\n",
    "# Columns that can be safely ordinal encoded\n",
    "good_label_cols = [col for col in object_cols if \n",
    "                   set(X_valid[col]).issubset(set(X_train[col]))]\n",
    "        \n",
    "# Problematic columns that will be dropped from the dataset\n",
    "bad_label_cols = list(set(object_cols)-set(good_label_cols))\n",
    "        \n",
    "print('Categorical columns that will be ordinal encoded:', good_label_cols)\n",
    "print('\\nCategorical columns that will be dropped from the dataset:', bad_label_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilisez la cellule de code suivante pour coder en ordinal les données dans X_train et X_valid. Définissez les DataFrames prétraités sur label_X_train et label_X_valid, respectivement.\n",
    "\n",
    "   -  Nous avons fourni le code ci-dessous pour supprimer les colonnes catégorielles dans bad_label_cols de l'ensemble de données.\n",
    "   -  Vous devez encoder de manière ordinale les colonnes catégorielles dans good_label_cols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Drop categorical columns that will not be encoded\n",
    "label_X_train = X_train.drop(bad_label_cols, axis=1)\n",
    "label_X_valid = X_valid.drop(bad_label_cols, axis=1)\n",
    "\n",
    "# Apply ordinal encoder \n",
    "____ # Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MAE from Approach 2 (Ordinal Encoding):\") \n",
    "print(score_dataset(label_X_train, label_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of unique entries in each column with categorical data\n",
    "object_nunique = list(map(lambda col: X_train[col].nunique(), object_cols))\n",
    "d = dict(zip(object_cols, object_nunique))\n",
    "\n",
    "# Print number of unique entries by column, in ascending order\n",
    "sorted(d.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Étape 3 : one-hot encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Use as many lines of code as you need!\n",
    "\n",
    "OH_X_train = ____ # Your code here\n",
    "OH_X_valid = ____ # Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MAE from Approach 3 (One-Hot Encoding):\") \n",
    "print(score_dataset(OH_X_train, OH_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Générer des prédictions sur le jeu de test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation\n",
    "\n",
    "L'apprentissage automatique est un processus itératif.\n",
    "\n",
    "Vous serez confronté à des choix concernant les variables prédictives à utiliser, les types de modèles à utiliser, les arguments à fournir à ces modèles, etc. Jusqu'à présent, vous avez fait ces choix en fonction des données en mesurant la qualité du modèle avec un jeu de validation.\n",
    "\n",
    "Mais il y a quelques inconvénients à cette approche. Pour voir cela, imaginez que vous avez un jeu de données avec 5 000 lignes. Vous conserverez généralement environ 20 % des données sous forme de jeu de données de validation, soit 1 000 lignes. Mais cela laisse une chance aléatoire dans la détermination des scores du modèle. C'est-à-dire qu'un modèle pourrait bien fonctionner sur un ensemble de 1 000 lignes, même s'il serait inexact sur 1 000 lignes différentes.\n",
    "\n",
    "À l'extrême, vous pourriez imaginer n'avoir qu'une seule ligne de données dans l'ensemble de validation. Si vous comparez des modèles alternatifs, celui qui fait les meilleures prédictions sur un seul point de données sera principalement une question de chance !\n",
    "\n",
    "En général, plus le jeu de validation est grand, moins il y a d'aléatoire (alias \"bruit\") dans notre mesure de la qualité du modèle, et plus il sera fiable. Malheureusement, nous ne pouvons obtenir un grand jeu de validation qu'en supprimant des lignes de nos données d'entraînement, et des ensembles de données d'entraînement plus petits signifient des modèles pires !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En validation croisée, nous exécutons notre processus de modélisation sur différents sous-ensembles de données pour obtenir plusieurs mesures de la qualité du modèle.\n",
    "\n",
    "Par exemple, nous pourrions commencer par diviser les données en 5 parties, chacune représentant 20 % du jeu de données complet. Dans ce cas, nous disons que nous avons divisé les données en 5 \"folds\".\n",
    "\n",
    "Ensuite, nous effectuons une expérience pour chaque `fold` :\n",
    "\n",
    "   - Dans l'expérience 1, nous utilisons le premier fold comme jeu de validation et tout le reste comme données d'apprentissage. Cela nous donne une mesure de la qualité du modèle basée sur un jeu de validation de 20 %.\n",
    "   - Dans l'expérience 2, nous conservons les données du deuxième fold (et utilisons tout sauf le deuxième fold pour entraîner le modèle). Ce 2e fold est ensuite utilisé pour obtenir une deuxième estimation de la qualité du modèle.\n",
    "   - Nous répétons ce processus, en utilisant chaque fold une fois comme jeu de validation. En résumé, 100 % des données sont utilisées comme jeu de validation à un moment donné, et nous nous retrouvons avec une mesure de la qualité du modèle basée sur toutes les lignes de l'ensemble de données (même si nous n'utilisons pas toutes les lignes simultanément) ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quand utiliser la validation croisée ?\n",
    "La validation croisée donne une mesure plus précise de la qualité du modèle, ce qui est particulièrement important si vous prenez de nombreuses décisions de modélisation. Cependant, son exécution peut prendre plus de temps, car elle estime plusieurs modèles (un pour chaque fold).\n",
    "\n",
    "Alors, compte tenu de ces compromis, quand devriez-vous utiliser chaque approche ?\n",
    "\n",
    "   -  Pour les petits ensembles de données, où la charge de calcul supplémentaire n'est pas un gros problème, vous devez exécuter une validation croisée.\n",
    "   -  Pour les ensembles de données plus volumineux, un seul ensemble de validation est suffisant. Votre code s'exécutera plus rapidement et vous disposerez peut-être de suffisamment de données pour qu'il soit peu nécessaire d'en réutiliser certaines pour la rétention.\n",
    "   \n",
    "Il n'y a pas de seuil simple pour ce qui constitue un grand ou un petit ensemble de données. Mais si votre modèle prend quelques minutes ou moins à exécuter, cela vaut probablement la peine de passer à la validation croisée.\n",
    "\n",
    "Vous pouvez également exécuter une validation croisée et voir si les scores de chaque expérience semblent proches. Si chaque expérience donne les mêmes résultats, un seul ensemble de validation est probablement suffisant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the data\n",
    "train_data = pd.read_csv('../Data/data3/train.csv', index_col='Id')\n",
    "test_data = pd.read_csv('../Data/data3/test.csv', index_col='Id')\n",
    "\n",
    "# Remove rows with missing target, separate target from predictors\n",
    "train_data.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "y = train_data.SalePrice              \n",
    "train_data.drop(['SalePrice'], axis=1, inplace=True)\n",
    "\n",
    "# Select numeric columns only\n",
    "numeric_cols = [cname for cname in train_data.columns if train_data[cname].dtype in ['int64', 'float64']]\n",
    "X = train_data[numeric_cols].copy()\n",
    "X_test = test_data[numeric_cols].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le pipeline ci-dessous utilisera SimpleImputer() pour remplacer les valeurs manquantes dans les données, avant d'utiliser RandomForestRegressor() pour entraîner un modèle de forêt aléatoire afin de faire des prédictions. Nous définissons le nombre d'arbres dans le modèle de forêt aléatoire avec le paramètre n_estimators, et la définition de random_state garantit la reproductibilité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "my_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', SimpleImputer()),\n",
    "    ('model', RandomForestRegressor(n_estimators=50, random_state=0))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le code ci-dessous utilise la fonction cross_val_score() pour obtenir l'erreur absolue moyenne (MAE), moyennée sur cinq folds différents. Rappelons que nous définissons le nombre de folds avec le paramètre cv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Multiply by -1 since sklearn calculates *negative* MAE\n",
    "scores = -1 * cross_val_score(my_pipeline, X, y,\n",
    "                              cv=5,\n",
    "                              scoring='neg_mean_absolute_error')\n",
    "\n",
    "print(\"Average MAE score:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1: Write a useful function**\n",
    "\n",
    "Dans cet exercice, vous utiliserez la validation croisée pour **sélectionner les paramètres d'un modèle d'apprentissage automatique**.\n",
    "\n",
    "Commencez par écrire une fonction get_score() qui rapporte la moyenne (sur trois folds de validation croisée) MAE d'un pipeline d'apprentissage automatique qui utilise :\n",
    "\n",
    "   -  les données en X et y pour créer des plis,\n",
    "   -  SimpleImputer() (avec tous les paramètres laissés par défaut) pour remplacer les valeurs manquantes, et\n",
    "   -  RandomForestRegressor() (avec random_state=0) pour s'adapter à un modèle de forêt aléatoire.\n",
    "\n",
    "Le paramètre n_estimators fourni à get_score() est utilisé lors de la définition du nombre d'arbres dans le modèle de forêt aléatoire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(n_estimators):\n",
    "    \"\"\"Return the average MAE over 3 CV folds of random forest model.\n",
    "    \n",
    "    Keyword argument:\n",
    "    n_estimators -- the number of trees in the forest\n",
    "    \"\"\"\n",
    "    # Replace this body with your own code\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2: Test different parameter values**\n",
    "\n",
    "Vous allez maintenant utiliser la fonction que vous avez définie à l'étape 1 pour évaluer les performances du modèle correspondant à huit valeurs différentes pour le nombre d'arbres dans la forêt aléatoire : 50, 100, 150, ..., 300, 350, 400.\n",
    "\n",
    "Stockez vos résultats dans les résultats d'un dictionnaire Python, où result[i] est le MAE moyen renvoyé par get_score(i)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = ____ # Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilisez la cellule suivante pour visualiser vos résultats de l'étape 2. Exécutez le code sans modifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(list(results.keys()), list(results.values()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3: Find the best parameter value**\n",
    "\n",
    "Compte tenu des résultats, quelle valeur pour n_estimateurs semble la meilleure pour le modèle de forêt aléatoire ? Utilisez votre réponse pour définir la valeur de n_estimators_best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators_best = ____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
